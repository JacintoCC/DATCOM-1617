#+TITLE: Trabajo autónomo II: Minería de flujo de datos
#+SUBTITLE: Máster en Ciencia de Datos e Ingeniería de Computadores - Minería de flujo de datos y series temporales
#+AUTHOR: Jacinto Carrasco Castillo - jacintocc@correo.ugr.es
#+DATE: 5 de mayo de 2017
#+OPTIONS: toc:2

#+begin_src emacs-lisp :results silent :exports none
(require 'ob-shell)
  (org-babel-do-load-languages 
   'org-babel-load-languages
   '((R . t) 
     (shell .t)
     (latex . t)))

(defun shk-fix-inline-images () 
  (when org-inline-image-overlays 
    (org-redisplay-inline-images))) 

#+end_src 



* Parte teórica

** Pregunta 1

 Explicar el problema de clasificación, los clasificadores utilizados
  en los experimentos de la sección 2, y en qué consisten los
  diferentes modos de evaluación/validación en  flujos de datos.

Los clasificadores utilizados han sido el =Hoeffding Tree= y el
=Hoeffding Tree Adaptativo=. El clasificador =Hoeffding Tree= se basa
en la idea de que una pequeña muestra puede ser suficiente para
escoger un atributo que nos permita escoger la clase de la instancia,
para lo que se asume que la distribución de datos generados durante el
flujo no varía en el tiempo. La versión adaptativa de este
clasificador usa =ADWIN= para comprobar el rendimiento de las rámas
del árbol para irlas modificando con nuevas ramas cuando su porcentaje
de acierto disminuye si las nuevas ramas son más precisas.

Los modos de evaluación en flujo de datos son:
	- Test-Then-Train, donde se usa cada nuevo dato para evaluar
          el modelo e inmediatamente después es usado para
          entenamiento;
	- Prequential evaluation, que incluye un mecanismo de ventana
          deslizante para olvidar los datos antiguos.
	- Heldout: Se reserva un número de datos para test y se
          entrena con el resto.

** Pregunta 2 

 Explicar en qué consiste el problema de /concept drift/ y qué
  técnicas conoce para resolverlo en clasificación.


Nos referimos con /Concept drift/ a las situaciones en las que el
fenómeno estudiado sufre variaciones en sus propiedades estadísticas a
lo largo del tiempo, por lo que debemos ser capaces de detectar estas
variaciones y reaprender un modelo para ajustarnos a estas nuevas
circunstancias. 

* Parte práctica

** Entrenamiento offline y evaluación posterior
*** Hoeffding Tree
  Entrenar un clasificador =HoeffdingTree= /offline/ (aprender modelo
  únicamente),sobre un total de 1.000.000 de instancias procedentes de
  un flujo obtenido por el generador =WaveFormGenerator= con semilla
  aleatoria igual a 2. Evaluar posteriormente (sólo evaluación) con
  1.000.000 de instancias generadas por el mismo tipo de generador,
  con semilla aleatoria igual a 4. Repita el proceso varias veces con
  la misma semilla en evaluación y diferentes semillas en
  entrenamiento. Anotar los valores de porcentajes de aciertos en la
  clasificación y estadístico Kappa.


Realizamos el aprendizaje del clasificador =HoeffdingTree= con un flujo
generado con semilla $2$.

#+NAME: Learn Model Off
#+CAPTION: "Aprendizaje HoeffdingTree"
#+BEGIN_SRC bash :eval no-export
java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask \
  "LearnModel -l trees.HoeffdingTree \
     -s (generators.WaveformGenerator -i 2) \
     -m 1000000 -O model1.moa"
#+END_SRC


Una vez mostrado el ejemplo de lo que sería el código, realizaremos la
evaluación de los modelos generados con las semillas
$\{2,10,15,20,25\}$ sobre un flujo de datos creado con la semilla $4$.

#+NAME: Evaluate Model Off
#+CAPTION: "Aprendizaje y evaluación HoeffdingTree con varias semillas"
#+BEGIN_SRC  bash :eval no-export
for seed in 2 10 15 20 25
do
   java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask \
      "EvaluateModel \
         -m (LearnModel -l trees.HoeffdingTree \
	    -s (generators.WaveformGenerator -i $seed) -m 1000000) \
	 -s (generators.WaveformGenerator -i 4) -i 1000000"
done
#+END_SRC

#+TBLNAME: Off
#+RESULTS: Evaluate Model Off
| classified      | instances  | =         | 1.000.000 |           |           |            |
| classifications | correct    | (percent) | =         | 84,512    |           |            |
| Kappa           | Statistic  | (percent) | =         | 76,77     |           |            |
| Kappa           | Temporal   | Statistic | (percent) | =         | 76,778    |            |
| Kappa           | M          | Statistic | (percent) | =         | 76,707    |            |
| model           | training   | instances | =         | 1.000.000 |           |            |
| model           | serialized | size      | (bytes)   | =         | 1.910.496 |            |
| tree            | size       | (nodes)   | =         | 309       |           |            |
| tree            | size       | (leaves)  | =         | 155       |           |            |
| active          | learning   | leaves    | =         | 155       |           |            |
| tree            | depth      | =         | 12        |           |           |            |
| active          | leaf       | byte      | size      | estimate  | =         | 12.191,123 |
| inactive        | leaf       | byte      | size      | estimate  | =         |        0.0 |
| byte            | size       | estimate  | overhead  | =         | 1,011     |            |
| classified      | instances  | =         | 1.000.000 |           |           |            |
| classifications | correct    | (percent) | =         | 84,578    |           |            |
| Kappa           | Statistic  | (percent) | =         | 76,869    |           |            |
| Kappa           | Temporal   | Statistic | (percent) | =         | 76,877    |            |
| Kappa           | M          | Statistic | (percent) | =         | 76,807    |            |
| model           | training   | instances | =         | 1.000.000 |           |            |
| model           | serialized | size      | (bytes)   | =         | 2.055.712 |            |
| tree            | size       | (nodes)   | =         | 335       |           |            |
| tree            | size       | (leaves)  | =         | 168       |           |            |
| active          | learning   | leaves    | =         | 168       |           |            |
| tree            | depth      | =         | 13        |           |           |            |
| active          | leaf       | byte      | size      | estimate  | =         | 12.102,048 |
| inactive        | leaf       | byte      | size      | estimate  | =         |        0.0 |
| byte            | size       | estimate  | overhead  | =         | 1,011     |            |
| classified      | instances  | =         | 1.000.000 |           |           |            |
| classifications | correct    | (percent) | =         | 84,648    |           |            |
| Kappa           | Statistic  | (percent) | =         | 76,974    |           |            |
| Kappa           | Temporal   | Statistic | (percent) | =         | 76,982    |            |
| Kappa           | M          | Statistic | (percent) | =         | 76,912    |            |
| model           | training   | instances | =         | 1.000.000 |           |            |
| model           | serialized | size      | (bytes)   | =         | 1.917.504 |            |
| tree            | size       | (nodes)   | =         | 313       |           |            |
| tree            | size       | (leaves)  | =         | 157       |           |            |
| active          | learning   | leaves    | =         | 157       |           |            |
| tree            | depth      | =         | 11        |           |           |            |
| active          | leaf       | byte      | size      | estimate  | =         | 12.078,268 |
| inactive        | leaf       | byte      | size      | estimate  | =         |        0.0 |
| byte            | size       | estimate  | overhead  | =         | 1,011     |            |
| classified      | instances  | =         | 1.000.000 |           |           |            |
| classifications | correct    | (percent) | =         | 84,568    |           |            |
| Kappa           | Statistic  | (percent) | =         | 76,853    |           |            |
| Kappa           | Temporal   | Statistic | (percent) | =         | 76,862    |            |
| Kappa           | M          | Statistic | (percent) | =         | 76,791    |            |
| model           | training   | instances | =         | 1.000.000 |           |            |
| model           | serialized | size      | (bytes)   | =         | 1.953.480 |            |
| tree            | size       | (nodes)   | =         | 319       |           |            |
| tree            | size       | (leaves)  | =         | 160       |           |            |
| active          | learning   | leaves    | =         | 160       |           |            |
| tree            | depth      | =         | 13        |           |           |            |
| active          | leaf       | byte      | size      | estimate  | =         |  12.074,85 |
| inactive        | leaf       | byte      | size      | estimate  | =         |        0.0 |
| byte            | size       | estimate  | overhead  | =         | 1,011     |            |
| classified      | instances  | =         | 1.000.000 |           |           |            |
| classifications | correct    | (percent) | =         | 84,646    |           |            |
| Kappa           | Statistic  | (percent) | =         | 76,971    |           |            |
| Kappa           | Temporal   | Statistic | (percent) | =         | 76,979    |            |
| Kappa           | M          | Statistic | (percent) | =         | 76,909    |            |
| model           | training   | instances | =         | 1.000.000 |           |            |
| model           | serialized | size      | (bytes)   | =         | 1.880.568 |            |
| tree            | size       | (nodes)   | =         | 309       |           |            |
| tree            | size       | (leaves)  | =         | 155       |           |            |
| active          | learning   | leaves    | =         | 155       |           |            |
| tree            | depth      | =         | 12        |           |           |            |
| active          | leaf       | byte      | size      | estimate  | =         | 11.997,987 |
| inactive        | leaf       | byte      | size      | estimate  | =         |        0.0 |
| byte            | size       | estimate  | overhead  | =         | 1,011     |            |

Mostramos a continuación el porcentaje de acierto en clasificación
obtenido para cada una de las semillas y la media de éstos.
#+BEGIN_EXPORT latex
% latex table generated in R 3.3.2 by xtable 1.8-2 package
% Thu May  4 16:07:07 2017
\begin{table}[ht]
\centering
\begin{tabular}{rlrr}
  \hline
 & Seed & Acc & Kappa \\ 
  \hline
1 & 2 & 84.51 & 76.77 \\ 
  2 & 10 & 84.58 & 76.87 \\ 
  3 & 15 & 84.65 & 76.97 \\ 
  4 & 20 & 84.57 & 76.85 \\ 
  5 & 25 & 84.65 & 76.97 \\ 
  6 & media & 84.59 & 76.89 \\ 
   \hline
\end{tabular}
\end{table}
#+END_EXPORT

*** Hoeffding Tree Adaptativo
- Repetir el paso anterior, sustituyendo el clasificador por
  HoeffdingTree adaptativo.

Realizamos directamente el aprendizaje para las semillas anteriores y
la evaluación sobre el flujo generado con semilla 2.

#+NAME: Evaluate Model Off Adaptativo
#+CAPTION: "Aprendizaje y evaluación HoeffdingTree Adaptativo"
#+BEGIN_SRC  bash :eval no-export 
for seed in 2 10 15 20 25
do
   java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask \
      "EvaluateModel \
         -m (LearnModel -l ntrees.HoeffdingAdaptiveTree
	    -s (generators.WaveformGenerator -i $seed) -m 1000000) \
	 -s (generators.WaveformGenerator -i 4) -i 1000000"
done
#+END_SRC

#+TBLNAME: OffAdap
#+RESULTS: Evaluate Model Off Adaptativo
| classified      | instances  | =         | 1.000.000 |           |           |     |
| classifications | correct    | (percent) | =         | 84,474    |           |     |
| Kappa           | Statistic  | (percent) | =         | 76,712    |           |     |
| Kappa           | Temporal   | Statistic | (percent) | =         | 76,721    |     |
| Kappa           | M          | Statistic | (percent) | =         | 76,65     |     |
| model           | training   | instances | =         | 1.000.000 |           |     |
| model           | serialized | size      | (bytes)   | =         | 3.450.008 |     |
| tree            | size       | (nodes)   | =         | 447       |           |     |
| tree            | size       | (leaves)  | =         | 217       |           |     |
| active          | learning   | leaves    | =         | 217       |           |     |
| tree            | depth      | =         | 15        |           |           |     |
| active          | leaf       | byte      | size      | estimate  | =         | 0.0 |
| inactive        | leaf       | byte      | size      | estimate  | =         | 0.0 |
| byte            | size       | estimate  | overhead  | =         | 1         |     |
| classified      | instances  | =         | 1.000.000 |           |           |     |
| classifications | correct    | (percent) | =         | 84,326    |           |     |
| Kappa           | Statistic  | (percent) | =         | 76,491    |           |     |
| Kappa           | Temporal   | Statistic | (percent) | =         | 76,499    |     |
| Kappa           | M          | Statistic | (percent) | =         | 76,427    |     |
| model           | training   | instances | =         | 1.000.000 |           |     |
| model           | serialized | size      | (bytes)   | =         | 3.631.992 |     |
| tree            | size       | (nodes)   | =         | 462       |           |     |
| tree            | size       | (leaves)  | =         | 225       |           |     |
| active          | learning   | leaves    | =         | 225       |           |     |
| tree            | depth      | =         | 13        |           |           |     |
| active          | leaf       | byte      | size      | estimate  | =         | 0.0 |
| inactive        | leaf       | byte      | size      | estimate  | =         | 0.0 |
| byte            | size       | estimate  | overhead  | =         | 1         |     |
| classified      | instances  | =         | 1.000.000 |           |           |     |
| classifications | correct    | (percent) | =         | 84,229    |           |     |
| Kappa           | Statistic  | (percent) | =         | 76,345    |           |     |
| Kappa           | Temporal   | Statistic | (percent) | =         | 76,353    |     |
| Kappa           | M          | Statistic | (percent) | =         | 76,281    |     |
| model           | training   | instances | =         | 1.000.000 |           |     |
| model           | serialized | size      | (bytes)   | =         | 3.170.912 |     |
| tree            | size       | (nodes)   | =         | 401       |           |     |
| tree            | size       | (leaves)  | =         | 172       |           |     |
| active          | learning   | leaves    | =         | 172       |           |     |
| tree            | depth      | =         | 13        |           |           |     |
| active          | leaf       | byte      | size      | estimate  | =         | 0.0 |
| inactive        | leaf       | byte      | size      | estimate  | =         | 0.0 |
| byte            | size       | estimate  | overhead  | =         | 1         |     |
| classified      | instances  | =         | 1.000.000 |           |           |     |
| classifications | correct    | (percent) | =         | 84,459    |           |     |
| Kappa           | Statistic  | (percent) | =         | 76,69     |           |     |
| Kappa           | Temporal   | Statistic | (percent) | =         | 76,698    |     |
| Kappa           | M          | Statistic | (percent) | =         | 76,627    |     |
| model           | training   | instances | =         | 1.000.000 |           |     |
| model           | serialized | size      | (bytes)   | =         | 3.251.408 |     |
| tree            | size       | (nodes)   | =         | 424       |           |     |
| tree            | size       | (leaves)  | =         | 204       |           |     |
| active          | learning   | leaves    | =         | 204       |           |     |
| tree            | depth      | =         | 14        |           |           |     |
| active          | leaf       | byte      | size      | estimate  | =         | 0.0 |
| inactive        | leaf       | byte      | size      | estimate  | =         | 0.0 |
| byte            | size       | estimate  | overhead  | =         | 1         |     |
| classified      | instances  | =         | 1.000.000 |           |           |     |
| classifications | correct    | (percent) | =         | 84,589    |           |     |
| Kappa           | Statistic  | (percent) | =         | 76,886    |           |     |
| Kappa           | Temporal   | Statistic | (percent) | =         | 76,894    |     |
| Kappa           | M          | Statistic | (percent) | =         | 76,823    |     |
| model           | training   | instances | =         | 1.000.000 |           |     |
| model           | serialized | size      | (bytes)   | =         | 3.378.712 |     |
| tree            | size       | (nodes)   | =         | 429       |           |     |
| tree            | size       | (leaves)  | =         | 207       |           |     |
| active          | learning   | leaves    | =         | 207       |           |     |
| tree            | depth      | =         | 14        |           |           |     |
| active          | leaf       | byte      | size      | estimate  | =         | 0.0 |
| inactive        | leaf       | byte      | size      | estimate  | =         | 0.0 |
| byte            | size       | estimate  | overhead  | =         | 1         |     |

#+NAME: Output Off Adaptativo
#+BEGIN_SRC R :var x=OffAdap :eval no-export :results output latex 
library(xtable)
seeds <- c(2,10,15,20,25)
acc <- x[seq(2, by = 14, length.out = 5), 5]
acc <- as.numeric(gsub(",",".",acc))
kappa <- x[seq(3, by = 14, length.out = 5), 5]
kappa <- as.numeric(gsub(",",".",kappa))

df <- data.frame("Seed" = c(seeds,"media"), 
                 "Acc" = c(acc,mean(acc)),
                 "Kappa" = c(kappa,mean(kappa)))
xtable(df)
#+END_SRC

Mostramos la tabla con las medidas obtenidas por este clasificador. 

#+RESULTS: Output Off Adaptativo
#+BEGIN_EXPORT latex
% latex table generated in R 3.3.2 by xtable 1.8-2 package
% Wed May  3 12:32:01 2017
\begin{table}[ht]
\centering
\begin{tabular}{rlrr}
  \hline
 & Seed & Acc & Kappa \\ 
  \hline
1 & 2 & 84.47 & 76.71 \\ 
  2 & 10 & 84.33 & 76.49 \\ 
  3 & 15 & 84.23 & 76.34 \\ 
  4 & 20 & 84.46 & 76.69 \\ 
  5 & 25 & 84.59 & 76.89 \\ 
  6 & media & 84.42 & 76.62 \\ 
   \hline
\end{tabular}
\end{table}
#+END_EXPORT

*** Comparación
- Responda a la pregunta: ¿Cree que algún clasificador es
  significativamente mejor que el otro en este tipo de problemas?
  Razone su respuesta.

Para realizar la comparación de los dos métodos realizaremos un test
estadístico sobre las cinco muestras obtenidas. El resultado que
esperamos obtener es que no haya una diferencia significativa entre
los algoritmos, ya que el aprendizaje se realiza /off line/ a partir
del conjunto total de datos. 

Como vemos, los resultados son muy similares, y según un test de
Wilcoxon aplicado sobre estos valores no podemos descartar que el
rendimiento sea equivalente.

#+CAPTION: "Ejecución de Test de Wilcoxon"
#+BEGIN_EXPORT latex

	\underline{Wilcoxon rank sum test}\\

data:  $x$ and $y$ \\
W = 22, p-value = 0.05556 \\
alternative hypothesis: true location shift is not equal to $0$ \\

#+END_EXPORT


** Entrenamiento online 
   
Los experimentos de los siguientes apartados se harán en línea de
comandos y volcaremos los resultados en ficheros =.csv= para realizar
posteriormente las gráficas y test estadísticos para las comparaciones
en =R=. Para ello definimos una función que nos recupere la
información relevante de los archivos =.csv=. Las variables en las que
nos fijaremos serán en el número de instancias, el porcentaje de
acierto, el estadístico Kappa, el número de nodos y la profundidad del
árbol. Para la comparación de cada apartado entre el modelo de
=HoeffdingTree= y el modelo que incluye adaptación, nos fijaremos en
la última iteración y en la media por iteraciones, para promediar
finalmente por la semilla. 

#+NAME: ReadCSV
#+BEGIN_SRC R :session r_session :exports code :results silent
readMoaOutput <- function(dir){
   files <- list.files(dir, full.names = T)
   lapply(files, function(f){
      info <- read.csv(f)[ ,c(1,5,6,11,14)]
      colnames(info) <- c("Instances", "Acc", "Kappa", "Nodes", "Depth")
      return(info)
   })
}

summaryMoaSeeds <- function(list.results){
   summary <- t(sapply(list.results,
          function(seed.results){
	  return(t(matrix(c(seed.results[nrow(seed.results),-1], 
	                apply(seed.results[ ,-1], 2, mean)), ncol = 2)))
	  }))
   summary <- matrix(unlist(summary), ncol = 8)
   colnames(summary) <- paste(c("Last","Mean"),
                              rep(c("Acc","Kappa","Nodes","Depth"),each=2),
			      sep=".")
   return(summary)
}

summaryMoa <- function(list.results){
   summary <- summaryMoaSeeds(list.results)
   summary <- matrix(apply(summary, 2, mean), ncol = 4)   
   colnames(summary) <- c("Acc","Kappa","Nodes","Depth")
   rownames(summary) <- c("Last", "Mean")
   return(summary)
}
#+END_SRC


*** Hoeffding Tree
- Entrenar un clasificador HoeffdingTree online, mediante el método
  Interleaved Test-Then-Train, sobre un total de 1.000.000 de
  instancias procedentes de un flujo obtenido por el generador
  WaveFormGenerator con semilla aleatoria igual a 2, con una
  frecuencia de muestreo igual a 10.000. Pruebe con otras semillas
  aleatorias. Anotar los valores de porcentajes de aciertos en la
  clasificación y estadístico Kappa.

Para usar el método =EvaluateInterleavedTestThenTrain= incluimos el
número de instancias pasándole el argumento =-i= y la frecuencia de
muestreo con =-f=.

#+NAME: OnlineHT
#+BEGIN_SRC  bash
for seed in 2 10 15 20 25 
do 
 java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask \
   "EvaluateInterleavedTestThenTrain \
    -l moa.classifiers.trees.HoeffdingTree \
    -s (generators.WaveformGenerator -i $seed) \
   -i 1000000 -f 10000" > Resultados/Online/Hoeff/hoeff-$seed.csv
done
#+END_SRC

#+NAME: OutputOnlineHoeffdingTree
#+BEGIN_SRC R :exports results :results output latex :session r_session
library(xtable)
online.hoeff <- readMoaOutput("Resultados/Online/Hoeff")
xtable(summaryMoa(online.hoeff))
#+END_SRC

#+RESULTS: OutputOnlineHoeffdingTree
#+BEGIN_EXPORT latex
% latex table generated in R 3.3.2 by xtable 1.8-2 package
% Fri May  5 10:41:07 2017
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Acc & Kappa & Nodes & Depth \\ 
  \hline
Last & 83.88 & 75.82 & 317.00 & 12.20 \\ 
  Mean & 82.98 & 74.47 & 157.02 & 8.94 \\ 
   \hline
\end{tabular}
\end{table}
#+END_EXPORT

*** Hoeffding Tree Adaptativo
- Repetir el paso anterior, sustituyendo el clasificador por
  HoeffdingTree adaptativo.


#+NAME: EvalOnlineAdap
#+CAPTION: "Aprendizaje Online Hoeffding Tree Adaptativo"
#+BEGIN_SRC  bash
for seed in 2 10 15 20 25 
do 
 java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask \
    "EvaluateInterleavedTestThenTrain \
      -l moa.classifiers.trees.HoeffdingAdaptiveTree \
        -s (generators.WaveformGenerator -i $seed) \
	-i 1000000 -f 10000" > Resultados/Online/Adap/adap-$seed.csv
done
#+END_SRC

#+NAME: OnlineAdap
#+BEGIN_SRC R :exports results :results output latex :session r_session
online.adap <- readMoaOutput("Resultados/Online/Adap")
xtable(summaryMoa(online.adap))
#+END_SRC

#+RESULTS: OnlineAdap
#+BEGIN_EXPORT latex
% latex table generated in R 3.3.2 by xtable 1.8-2 package
% Fri May  5 10:54:42 2017
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Acc & Kappa & Nodes & Depth \\ 
  \hline
Last & 83.84 & 75.76 & 432.60 & 13.80 \\ 
  Mean & 83.06 & 74.59 & 214.65 & 10.18 \\ 
   \hline
\end{tabular}
\end{table}
#+END_EXPORT

*** Comparación
- Responda a la pregunta: ¿Cree que algún clasificador es mejor que el
  otro en este tipo de problemas? Razone su respuesta.

#+NAME: Comparación Online
#+BEGIN_SRC R :session r_session :eval no-export :exports results :results output latex
acc.online.hoeff <- summaryMoaSeeds(online.hoeff)
acc.online.adap <- summaryMoaSeeds(online.adap)
print(wilcox.test(acc.online.hoeff,acc.online.adap,exact = F))
#+END_SRC

  Podemos observar en los resultados medios que no hay diferencias
  significativas entre los dos métodos. Si aplicamos el test de
  Wilcoxon obtenemos un $p$-valor muy superior al nivel de
  significación, con lo que no podemos descartar que su acierto sea
  idéntico. 

#+RESULTS: Comparación Online
#+BEGIN_EXPORT latex

	underline{Wilcoxon rank sum test with continuity correction}\\

data:  Accuracy in Online Hoeffding Tree and Accuracy in Online Adaptive\\
W = 743, p-value = 0.5866\\
alternative hypothesis: true location shift is not equal to 0\\
#+END_EXPORT

** Entrenamiento online en datos con /concept drift/.

*** Hoeffding Tree
- Entrenar un clasificador HoeffdingTree online, mediante el método
  Interleaved Test-Then-Train, sobre un total de 2.000.000 de
  instancias muestreadas con una frecuencia de 100.000, sobre datos
  procedentes de un generador de flujos RandomRBFGeneratorDrift, con
  semilla aleatorio igual a 1 para generación de modelos y de
  instancias, generando 2 clases, 7 atributos, 3 centroides en el
  modelo, drift en todos los centroides y velocidad de cambio igual a
  0.001. Pruebe con otras semillas aleatorias. Anotar los valores de
  porcentajes de aciertos en la clasificación y estadístico
  Kappa. Compruebe la evolución de la curva de aciertos en la GUI de
  MOA.

En estos experimentos la semilla también afectará a la generación del
/concept drift/. 

#+NAME: EvalDrift
#+CAPTION: "Aprendizaje Online Hoeffding Tree - Concept Drift"
#+BEGIN_SRC  bash
for seed in 1 2 314 261 832
do
   java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask \
    "EvaluateInterleavedTestThenTrain \
      -l moa.classifiers.trees.HoeffdingTree \
        -s (generators.RandomRBFGeneratorDrift \
	       -r $seed -i $seed -s 0.001 -k 3 -a 7 -n 3) \
	-i 2000000 -f 100000" > Resultados/Drift/Hoeff/hoeff-$seed.csv
done
#+END_SRC

#+RESULTS: EvalDrift


#+NAME: DriftHoeff
#+BEGIN_SRC R :exports results :results output latex :session r_session
drift.hoeff <- readMoaOutput("Resultados/Drift/Hoeff")
xtable(summaryMoa(drift.hoeff))
#+END_SRC

#+RESULTS: DriftHoeff
#+BEGIN_EXPORT latex
% latex table generated in R 3.3.2 by xtable 1.8-2 package
% Fri May  5 12:42:54 2017
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Acc & Kappa & Nodes & Depth \\ 
  \hline
Last & 77.47 & 36.73 & 1875.40 & 16.40 \\ 
  Mean & 79.08 & 41.61 & 1023.70 & 14.36 \\ 
   \hline
\end{tabular}
\end{table}
#+END_EXPORT

*** Adaptativo

#+NAME: OHTAConcept Drift
#+CAPTION: "Aprendizaje Online Hoeffding Tree Adaptativo - Concept Drift"
#+BEGIN_SRC  bash
for seed in 1 2 314 261 832
do 
 java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask \
    "EvaluateInterleavedTestThenTrain \
      -l moa.classifiers.trees.HoeffdingAdaptiveTree \
        -s (generators.RandomRBFGeneratorDrift \
	       -r $seed -i $seed -s 0.001 -k 3 -a 7 -n 3) \
	-i 2000000 -f 100000" > Resultados/Drift/Adap/adap-$seed.csv
done
#+END_SRC


#+NAME: Drift Adap
#+BEGIN_SRC R :exports results :results output latex :session r_session
drift.adap <- readMoaOutput("Resultados/Drift/Adap")
xtable(summaryMoa(drift.adap))
#+END_SRC

#+RESULTS: Drift Adap
#+BEGIN_EXPORT latex
% latex table generated in R 3.3.2 by xtable 1.8-2 package
% Fri May  5 11:38:48 2017
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Acc & Kappa & Nodes & Depth \\ 
  \hline
Last & 92.93 & 81.17 & 2936.60 & 2.80 \\ 
  Mean & 92.97 & 81.30 & 1558.87 & 2.37 \\ 
   \hline
\end{tabular}
\end{table}
#+END_EXPORT


*** Comparación

#+NAME: Comparación Drift
#+BEGIN_SRC R :session r_session :eval no-export :exports results :results output latex
acc.drift.hoeff <- summaryMoaSeeds(drift.hoeff)[ ,"Mean.Acc"]
acc.drift.adap <- summaryMoaSeeds(drift.adap)[,"Mean.Acc"]
print(wilcox.test(acc.drift.hoeff,acc.drift.adap,exact = F))
#+END_SRC

  Podemos observar en los resultados medios que no hay diferencias
  significativas entre los dos métodos. Si aplicamos el test de
  Wilcoxon obtenemos un $p$-valor inferior a 0.01, con lo que podemos
  rechazar la hipótesis de que sean equivalentes. Si observamos las
  tablas de cada modelo, observamos que el =HoeffdingTree= tiene una
  profundidad mucho mayor, lo que significa que el modelo va
  aprendiendo pero no va olvidando lo ocurrido anteriormente que ya no
  funciona y por tanto sufre con los /concept drifts/.

#+RESULTS: Comparación Drift
#+BEGIN_EXPORT latex

	\underline{Wilcoxon rank sum test with continuity correction}\\

data:  acc.drift.hoeff and acc.drift.adap\\
W = 0, p-value = 0.01219\\
alternative hypothesis: true location shift is not equal to 0
#+END_EXPORT



** Entrenamiento online en datos con /concept drift/, incluyendo mecanismos para olvidar instancias pasadas.

*** Ventana deslizante
- Repita la experimentación del apartado anterior, cambiando el método
  de evaluación “Interleaved Test-Then-Train” por el método de
  evaluación “Prequential”, con una ventana deslizante de tamaño 1.000.

**** Hoeffding

#+NAME: Eval Ventana 
#+CAPTION: "Aprendizaje Online Hoeffding Tree - Concept Drift - Ventana"
#+BEGIN_SRC  bash :eval no-export 
for seed in 1 2 314 261 832
do
  java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask \
    "EvaluatePrequential \
       -l trees.HoeffdingTree \
          -s (generators.RandomRBFGeneratorDrift -s 0.001 \
	       -r $seed -i $seed -s 0.001 -k 3 -a 7 -n 3) \
       -i 2000000" > Resultados/Window/Hoeff/hoeff-$seed.csv
done
#+END_SRC

#+RESULTS: Eval Ventana

#+NAME: Ventana
#+BEGIN_SRC R :exports results :results output latex :session r_session
window.hoeff <- readMoaOutput("Resultados/Window/Hoeff")
xtable(summaryMoa(window.hoeff))
#+END_SRC

#+RESULTS: Ventana
#+BEGIN_EXPORT latex
% latex table generated in R 3.3.2 by xtable 1.8-2 package
% Fri May  5 12:44:05 2017
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Acc & Kappa & Nodes & Depth \\ 
  \hline
Last & 75.04 & 31.35 & 1875.40 & 16.40 \\ 
  Mean & 77.79 & 36.27 & 1023.70 & 14.36 \\ 
   \hline
\end{tabular}
\end{table}
#+END_EXPORT

**** Hoeffding Adaptativo

#+NAME: OHTCDAVentana
#+CAPTION: "Aprendizaje Online Hoeffding Tree Adaptativo - Concept Drift - Ventana"
#+BEGIN_SRC  bash :eval no-export 
for seed in 1 2 314 261 832
do
  java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask \
    "EvaluatePrequential \
       -l trees.HoeffdingAdaptiveTree \
          -s (generators.RandomRBFGeneratorDrift -s 0.001 \
	       -r $seed -i $seed -s 0.001 -k 3 -a 7 -n 3) \
       -i 2000000" > Resultados/Window/Adap/adap-$seed.csv
done
#+END_SRC

#+RESULTS: OHTCDAVentana

#+NAME: Ventana Adap
#+BEGIN_SRC R :exports results :results output latex :session r_session
window.adap <- readMoaOutput("Resultados/Window/Adap")
xtable(summaryMoa(window.adap))
#+END_SRC

#+RESULTS: Ventana Adap
#+BEGIN_EXPORT latex
% latex table generated in R 3.3.2 by xtable 1.8-2 package
% Fri May  5 12:49:50 2017
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Acc & Kappa & Nodes & Depth \\ 
  \hline
Last & 92.96 & 82.37 & 2936.60 & 2.80 \\ 
  Mean & 92.88 & 81.00 & 1558.87 & 2.37 \\ 
   \hline
\end{tabular}
\end{table}
#+END_EXPORT

*** Comparación
- ¿Qué efecto se nota en ambos clasificadores? ¿A qué es debido?
  Justifique los cambios relevantes en los resultados de los
  clasificadores

#+NAME: Comparación Window
#+BEGIN_SRC R :session r_session :eval no-export :exports results :results output latex
acc.window.hoeff <- summaryMoaSeeds(window.hoeff)[ ,"Mean.Acc"]
acc.window.adap <- summaryMoaSeeds(window.adap)[,"Mean.Acc"]
print(wilcox.test(acc.window.hoeff,acc.window.adap,exact = F))
#+END_SRC

#+RESULTS: Comparación Window
#+BEGIN_EXPORT latex

	Wilcoxon rank sum test with continuity correction

data:  acc.window.hoeff and acc.window.adap
W = 0, p-value = 0.01219
alternative hypothesis: true location shift is not equal to 0
#+END_EXPORT


A pesar de incluir el mecanismo para olvidar instancias antiguas, el
=HoeffdingTree= adaptativo sigue siendo mejor significativamente que
el modelo no adaptativo. Esto se porduce debido a que al haber un
cambio en el flujo de datos, el modelo adaptativo reacciona mejor,
desechando la información aprendida antes de que las instancias de la
situación anterior desaparezcan por antiguas.
** Entrenamiento online en datos con concept drift, incluyendo mecanismos para reinicializar modelos tras la detección de cambios de concepto.

- Repita la experimentación del apartado 2.3, cambiando el modelo
  (learner) a un clasificador simple basado en reemplazar el
  clasificador actual cuando se detecta un cambio de concepto
  (SingleClassifierDrift). Como detector de cambio de concepto, usar
  el método DDM con sus parámetros por defecto. Como modelo a
  aprender, usar un clasificador HoeffdingTree.

*** Hoeffding Tree
#+NAME: Eval Reboot
#+CAPTION: "Aprendizaje Online - Concept Drift - Window - Reboot"
#+BEGIN_SRC  bash :eval no-export 
for seed in 1 2 314 261 832
do
  java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask \
    "EvaluatePrequential \
      -l (drift.SingleClassifierDrift -l trees.HoeffdingTree) \
          -s (generators.RandomRBFGeneratorDrift -s 0.001 \
	       -r $seed -i $seed -s 0.001 -k 3 -a 7 -n 3) \
       -i 2000000" > Resultados/Reboot/Hoeff/hoeff-$seed.csv
done
#+END_SRC

#+RESULTS: Eval Reboot


#+NAME: Reboot
#+BEGIN_SRC R :exports results :results output latex :session r_session
reboot.hoeff <- readMoaOutput("Resultados/Reboot/Hoeff")
xtable(summaryMoa(reboot.hoeff))
#+END_SRC

#+RESULTS: Reboot
#+BEGIN_EXPORT latex
% latex table generated in R 3.3.2 by xtable 1.8-2 package
% Fri May  5 14:09:05 2017
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Acc & Kappa & Nodes & Depth \\ 
  \hline
Last & 90.36 & 68.49 & 41.60 & 69.80 \\ 
  Mean & 92.20 & 75.82 & 52.68 & 24.58 \\ 
   \hline
\end{tabular}
\end{table}
#+END_EXPORT


*** Hoeffding Tree Adaptativo
- Repita el paso anterior cambiando el clasificador HoeffdingTree por
  un clasificador HoeffdingTree adaptativo.
#+NAME: OCDAdaptive-LR
#+CAPTION: "Aprendizaje Online Hoeffding Tree - Concept Drift - Ventana - Adaptive"
#+BEGIN_SRC  bash :eval no-export 
for seed in 1 2 314 261 832
do
  java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask \
    "EvaluatePrequential \
      -l (drift.SingleClassifierDrift -l trees.HoeffdingAdaptiveTree) \
          -s (generators.RandomRBFGeneratorDrift -s 0.001 \
	       -r $seed -i $seed -s 0.001 -k 3 -a 7 -n 3) \
       -i 2000000" > Resultados/Reboot/Adap/adap-$seed.csv
done
#+END_SRC

#+RESULTS: OCDAdaptive-LR


#+NAME: Reboot Adap
#+BEGIN_SRC R :exports results :results output latex :session r_session
reboot.adap <- readMoaOutput("Resultados/Reboot/Adap")
xtable(summaryMoa(reboot.adap))
#+END_SRC

#+RESULTS: Reboot Adap
#+BEGIN_EXPORT latex
% latex table generated in R 3.3.2 by xtable 1.8-2 package
% Fri May  5 14:14:03 2017
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Acc & Kappa & Nodes & Depth \\ 
  \hline
Last & 93.58 & 82.22 & 0.00 & 367.80 \\ 
  Mean & 93.25 & 81.98 & 11.77 & 134.18 \\ 
   \hline
\end{tabular}
\end{table}
#+END_EXPORT

*** Comparación

#+NAME: Comparación Reboot
#+BEGIN_SRC R :session r_session :eval no-export :exports results :results output latex
acc.reboot.hoeff <- summaryMoaSeeds(reboot.hoeff)[ ,"Mean.Acc"]
acc.reboot.adap <- summaryMoaSeeds(reboot.adap)[,"Mean.Acc"]
print(wilcox.test(acc.reboot.hoeff,acc.reboot.adap,exact = F))
#+END_SRC

#+RESULTS: Comparación Reboot
#+BEGIN_EXPORT latex

	\underline{Wilcoxon rank sum test with continuity correction}\\

data:  acc.reboot.hoeff and acc.reboot.adap\\
W = 11, p-value = 0.8345\\
alternative hypothesis: true location shift is not equal to 0\\
#+END_EXPORT

** Comparación final

- Responda a la siguiente pregunta: ¿Qué diferencias se producen entre
  los métodos de los apartados 2.3, 2.4 y 2.5? Explique similitudes y
  diferencias entre las diferentes metodologías, y discuta los
  resultados obtenidos por cada una de ellas en el flujo de datos
  propuesto.

#+NAME: Comparación Global 
#+BEGIN_SRC R :session r_session :eval no-export :exports none
comp.df <- data.frame(Iteration = rep(drift.hoeff[[1]]$Instances, 6),
                      Acc = c(drift.hoeff[[1]]$Acc, drift.adap[[1]]$Acc,
			      window.hoeff[[1]]$Acc, window.adap[[1]]$Acc,
			      reboot.hoeff[[1]]$Acc, reboot.adap[[1]]$Acc),
                      Model = rep(c("H","A"), each = nrow(drift.hoeff[[1]]), times = 3),
		      Method = rep(c("Drift","Window","Reboot"), each = 2*nrow(drift.hoeff[[1]])))
library(ggplot2)
library(dplyr)
#+END_SRC


#+NAME: Comparación Método 
#+BEGIN_SRC R :session r_session :eval no-export :exports results :results output graphics :file grafico2.pdf
graphic <- ggplot(comp.df, aes(x= Iteration, y = Acc, color = Method, linetype = Model)) +
   geom_line() + 
   labs(title = "Comparación ")
print(graphic)
#+END_SRC

#+RESULTS: Comparación Método
[[file:grafico2.pdf]]


En la gráfica vemos cómo el modelo adaptativo es en general mejor,
aunque no hay diferencias significativas cuando reinicializa debido a
que se convierte en adaptativo al reaprender el modelo. 
