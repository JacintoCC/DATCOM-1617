#+TITLE: Práctica Spark
#+SUBTITLE: Big Data & Cloud Computing
#+DATE: 5 de junio de 2017
#+OPTIONS: toc:nil
#+LaTeX_HEADER: \usemintedstyle{lovelace}

*Práctica de Big Data*: Resolver el problema de clasificación no
 balanceada asociado utilizando como medida $TPR \times TNR$ en test
 (el producto de los porcentajes de clasificación en cada clase). Hay
 que resolver el problema utilizando la biblioteca MLLib para los
 algoritmos Decision Tree y Random Forest, y los algoritmos de
 preprocesamiento ROS y RUS. 



Los algoritmos de preprocesamiento utilizados han sido obtenidos del
[[https://github.com/gDanix/Imb-sampling-ROS_and_RUS][repositorio]] del compañero del máster Daniel Sánchez Trujillo, que es a
su vez un /fork/ del repositorio indicado de Sara del Río, con la
diferencia de que éste permite ser usado como biblioteca y manejar los
conjuntos preprocesados dentro del propio programa sin necesidad de
que éstos sean escritos en disco.

* Experimentación

Para la experimentación se han ejecutado tanto en local como en el
servidor las combinaciones de los métodos de preprocesamiento ROS y
RUS con los modelos de aprendizaje =Decision Tree= y =Random Forest=
de la biblioteca =MLLib=. Tomaremos para cada ejecución los valores de
TPR, TNR y el producto de ambos. Para eso se ha implementado la
[[measures][función]] =getResults= que, a partir de la combinación de predicciones
y valores reales y haciendo uso de la función =truePositiveRate= de la
clase =MulticlassMetrics=, nos devuelve un =Array= con los valores
requeridos.

Los parámetros que usaremos serán los indicados en las transparencias
de clase tanto para =DecisionTree=:

#+NAME: parameters
#+BEGIN_SRC scala
val numClasses = converter.getNumClassFromHeader()
val categoricalFeaturesInfo = Map[Int,Int]()
val impurity = "entropy"
val maxBins = 100
val maxDepth = 10
#+END_SRC
como para =RandomForest=:

#+BEGIN_SRC scala
val impurity = "gini"
val maxBins = 32
val maxDepth = 4
val numTrees = 30
#+END_SRC

Para evaluar el modelo =model=, realizaremos la predicción sobre cada
instancia en el conjunto de test:

#+NAME: evaluation
#+BEGIN_SRC scala
val predictions = test.map{
  point =>
  val prediction = model.predict(point.features)
  (prediction, point.label)
}.persist

var results = getResults(predictions)
#+END_SRC
** Modelos

Comenzamos ejecutando los métodos de aprendizaje sin ningún
preprocesamiento.

- *Decision Trees*
#+NAME: DT
#+BEGIN_SRC scala
val model = DecisionTree.trainClassifier(train, numClasses,
  categoricalFeaturesInfo, impurity, maxDepth, maxBins)
#+END_SRC

- *Random Forest*
#+BEGIN_SRC scala
var size_forest = 70
var model = RandomForest.trainClassifier(train, numClasses,
  categoricalFeaturesInfo, size_forest, "auto", impurity, maxDepth, maxBins)
#+END_SRC

* Preprocesamiento

** Undersampling

Para aplicar /Random Undersampling/, habremos importado la biblioteca 

=Imbalanced= mencionada previamente y modificamos el conjunto de
entrenamiento con:

#+BEGIN_SRC scala
val minorityLabel = "1"
val majorityLabel = "0"

val preprocesedTrain = runRUS(train, minorityLabel, majorityLabel)  
#+END_SRC


** Oversampling

Para aplicar /Random Oversampling/, probaremos con diferentes
porcentajes, que irán desde 75\%, lo que significaría reducir aún más
la clase minoritaria, hasta 200\%, lo que supone duplicar el número de
instancias de la clase positiva con un paso de 25\%:


#+BEGIN_SRC scala
val minorityLabel = "1"
val majorityLabel = "0"

val preprocesedTrain = runROS(train, minorityLabel, majorityLabel,percentage)  
#+END_SRC


** Discretización y FS

Se ha aplicado también el discretizador y la selección de
características explicada en clase de la biblioteca de Sergio Ramírez.

#+BEGIN_SRC scala
val categoricalFeat: Option[Seq[Int]] = None

val nBins = 15
val maxByPart = 10000

val discretizer = MDLPDiscretizer.train(train, categoricalFeat, nBins, maxByPart)
val discrete = train.map(i =>
  LabeledPoint(i.label, discretizer.transform(i.features)))
  .cache()

val discreteTest = test.map(i =>
  LabeledPoint(i.label,discretizer.transform(i.features)))
  .cache()

/*
 * Feature Selection
 */

val criterion = new InfoThCriterionFactory("mrmr")
val nToSelect = 10
val nPartitions = 6

val featureSelector = new InfoThSelector(criterion,nToSelect,nPartitions)
  .fit(discrete)
val reduced = discrete.map(i =>
  LabeledPoint(i.label, featffureSelector.transform(i.features)))
  .cache()

val reducedTest = discreteTest.map(i =>
  LabeledPoint(i.label, featureSelector.transform(i.features)))
  .cache()
#+END_SRC

* Resultados


  Tras probar con los parámetros visto en clase, cuyos resultados están
  incluidos en la Tabla[[tab-resultados]], se ha lanzado también una
  ejecución en el servidor incrementando el número de características
  seleccionadas, y se incluyen los resultados en la Tabla[[tab-FS]].

  #+NAME: tab-resultados
  #+CAPTION: Tabla de resultados
  |---+------+--------+-----+----+--------+--------+----------------|
  |   | Alg. | Prepr. |   % | FS |    TPR |    TNR | TPR \times TNR |
  |---+------+--------+-----+----+--------+--------+----------------|
  | / | <>   | <      |     |  > |      < |      > |             <> |
  | # | DT   | -      |     |    | 0.8928 | 0.4672 |         0.4171 |
  | # |      | RUS    |   - |    | 0.7131 | 0.7234 |         0.5159 |
  | # |      | ROS    |  75 |    | 0.7753 | 0.6584 |         0.5105 |
  | # |      |        | 125 |    | 0.6647 | 0.7650 |         0.5085 |
  | # |      |        | 150 |    | 0.5921 | 0.8232 |         0.4874 |
  | # |      |        | 175 |    | 0.5565 | 0.8468 |         0.4712 |
  | # |      |        | 200 |    | 0.5146 | 0.8698 |         0.4476 |
  | # |      | -      |     | 10 | 0.9098 | 0.3727 |         0.3391 |
  | # |      | RUS    |   - | 10 | 0.7116 | 0.6697 |         0.4765 |
  | # |      | ROS    |  75 | 10 | 0.7969 | 0.5671 |         0.4520 |
  | # |      |        | 125 | 10 | 0.6170 | 0.7563 |         0.4667 |
  | # |      |        | 150 | 10 | 0.5389 | 0.8143 |         0.4389 |
  | # |      |        | 175 | 10 | 0.4644 | 0.8585 |         0.3987 |
  | # |      |        | 200 | 10 | 0.4272 | 0.8780 |         0.3751 |
  | # | RF   | -      |     |    | 0.9857 | 0.1196 |         0.1179 |
  | # |      | RUS    |   - |    | 0.7157 | 0.6892 |         0.4932 |
  | # |      | ROS    |  75 |    | 0.8465 | 0.5147 |         0.4357 |
  | # |      |        | 125 |    | 0.5313 | 0.8255 |         0.4387 |
  | # |      |        | 150 |    | 0.4056 | 0.8945 |         0.3628 |
  | # |      |        | 175 |    | 0.2384 | 0.9608 |         0.2291 |
  | # |      |        | 200 |    | 0.1706 | 0.9754 |         0.1664 |
  | # |      | -      |     | 10 | 0.9467 | 0.2139 |         0.2025 |
  | # |      | RUS    |     | 10 | 0.6417 | 0.7045 |         0.4521 |
  | # |      | ROS    |  75 | 10 | 0.7810 | 0.5512 |         0.4305 |
  | # |      |        | 125 | 10 | 0.5470 | 0.7884 |         0.4313 |
  | # |      |        | 150 | 10 | 0.4918 | 0.8172 |         0.4019 |
  | # |      |        | 175 | 10 | 0.4019 | 0.8789 |         0.3533 |
  | # |      |        | 200 | 10 | 0.3159 | 0.9222 |         0.2914 |
  |---+------+--------+-----+----+--------+--------+----------------|


  #+NAME: tab-FS
  #+CAPTION: TPR \times TNR para selección de características
  |---+----+-----+-----+--------+--------+--------+--------|
  |   |    |     |     |     FS |        |        |        |
  |   |    |     |     |     10 |     20 |     50 |     80 |
  |---+----+-----+-----+--------+--------+--------+--------|
  | / | <  |     |   > |      < |        |        |      > |
  | # | DT | -   |     | 0.3391 | 0.3797 | 0.4277 | 0.4178 |
  | # |    | RUS |   - | 0.4785 | 0.5012 | 0.5122 | 0.5139 |
  | # |    | ROS |  75 | 0.4523 | 0.4813 | 0.5013 | 0.5038 |
  | # |    |     | 125 | 0.4696 | 0.4938 | 0.5063 | 0.5093 |
  | # |    |     | 150 | 0.4414 | 0.4635 | 0.4903 | 0.4879 |
  | # |    |     | 175 | 0.4061 | 0.4355 | 0.4581 | 0.4582 |
  |---+----+-----+-----+--------+--------+--------+--------|
  | # | RF | -   |     | 0.1923 | 0.1628 | 0.1740 | 0.1763 |
  | # |    | RUS |   - | 0.4530 | 0.4752 | 0.4912 | 0.4946 |
  | # |    | ROS |  75 | 0.4263 | 0.4493 | 0.4403 | 0.4482 |
  | # |    |     | 125 | 0.4266 | 0.4315 | 0.4414 | 0.4544 |
  | # |    |     | 150 | 0.3921 | 0.3834 | 0.3940 | 0.3788 |
  | # |    |     | 175 | 0.3290 | 0.2927 | 0.3231 | 0.3020 |
  |---+----+-----+-----+--------+--------+--------+--------|

En estas tablas vemos cómo en general los métodos de preprocesamiento
son útiles para la resolución del problema, tanto los métodos de
balanceo como la selección de características. También se observa cómo
para este problema /random undersampling/ tiene un mejor
comportamiento y también vemos que con 50 y 80 características se
obtienen resultados muy cercanos a los obtenidos con todas las
características.

* Anexo

  - Función para obtener los valores TPR, TNR y su producto.

  #+NAME: measures
  #+BEGIN_SRC scala
def getResults(predictions: RDD[(Double, Double)]): Array[Double] ={
  val metrics = new MulticlassMetrics(predictions)
  val tpr = metrics.truePositiveRate(0)
  val tnr = metrics.truePositiveRate(1)
  
  Array(tpr,tnr,tpr*tnr)
}
#+END_SRC
